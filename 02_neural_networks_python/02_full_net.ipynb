{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "662a93d1",
      "metadata": {
        "id": "662a93d1"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e19878bb",
      "metadata": {
        "id": "e19878bb"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "da412dba",
      "metadata": {
        "id": "da412dba",
        "outputId": "924d7be9-c8dc-4b33-c29f-2ce1219e9cd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(60000, 784)\n",
            "\n",
            "MNIST data loaded: train: 60000 test: 10000\n",
            "X_train: (60000, 784)\n",
            "y_train: (60000,)\n"
          ]
        }
      ],
      "source": [
        "# repeating the data prep from the previous notebook\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.astype(numpy.float32)\n",
        "x_test  = x_test.astype(numpy.float32)\n",
        "\n",
        "x_train /= 255.\n",
        "x_test  /= 255.\n",
        "\n",
        "print(x_train.shape)\n",
        "x_train = x_train.reshape(x_train.shape[0], numpy.prod(x_train[0,:,:].shape))\n",
        "x_test = x_test.reshape(x_test.shape[0], numpy.prod(x_test[0,:,:].shape))\n",
        "\n",
        "print(x_train.shape)\n",
        "y_train = y_train.astype(numpy.int32)\n",
        "y_test  = y_test.astype(numpy.int32)\n",
        "\n",
        "print()\n",
        "print('MNIST data loaded: train:',len(x_train),'test:',len(x_test))\n",
        "print('X_train:', x_train.shape)\n",
        "print('y_train:', y_train.shape)\n",
        "\n",
        "# one-hot encoding:\n",
        "nb_classes = 10\n",
        "y_train_onehot = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
        "y_test_onehot = tf.keras.utils.to_categorical(y_test, nb_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "302994b1",
      "metadata": {
        "id": "302994b1",
        "outputId": "ef7e066a-1204-40e6-a07d-d7b97c3bab63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b92f04abdcee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Need to run this on a computer instead of Google Colab to have it properly load the whole github folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfc_net\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTwoLayerNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fc_net'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# Here we import an implementation of a two-layer neural network \n",
        "# this code is based on pieces of the first assignment from Stanford's CSE231n course, \n",
        "# hosted at https://github.com/cs231n/cs231n.github.io with the MIT license\n",
        "\n",
        "# Need to run this on a computer instead of Google Colab to have it properly load the whole github folder\n",
        "from fc_net import TwoLayerNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e00e3de",
      "metadata": {
        "id": "4e00e3de"
      },
      "outputs": [],
      "source": [
        "num_features = x_train.shape[1] # this is the number of pixels\n",
        "# The weights are initialized from a normal distribution with standard deviation weight_scale\n",
        "model = TwoLayerNet(input_dim=num_features, hidden_dim=300, num_classes=nb_classes, weight_scale=.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32f7f1aa",
      "metadata": {
        "id": "32f7f1aa"
      },
      "outputs": [],
      "source": [
        "# here you can take a look if you want at the initial loss from an untrained network\n",
        "loss, gradients = model.loss(x_train, y_train_onehot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c43e3aa5",
      "metadata": {
        "id": "c43e3aa5"
      },
      "outputs": [],
      "source": [
        "# a simple implementation of stochastic gradient descent\n",
        "def sgd(model, gradients, learning_rate):\n",
        "    for p, w in model.params.items():\n",
        "        dw = gradients[p]\n",
        "        new_weights = w - learning_rate * dw\n",
        "        model.params[p] = new_weights\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8316228",
      "metadata": {
        "id": "c8316228"
      },
      "outputs": [],
      "source": [
        "# one training step\n",
        "def learn(model, x_train, y_train_onehot, learning_rate):\n",
        "    loss, gradients = model.loss(x_train, y_train_onehot)\n",
        "    model = sgd(model, gradients, learning_rate)\n",
        "    return loss, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81886e8c",
      "metadata": {
        "id": "81886e8c"
      },
      "outputs": [],
      "source": [
        "def accuracy(model, x, true_values):\n",
        "    scores = model.loss(x)\n",
        "    predictions = numpy.argmax(scores, axis=1)\n",
        "    N = predictions.shape[0]\n",
        "    acc = (true_values == predictions).sum() / N\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49754891",
      "metadata": {
        "id": "49754891"
      },
      "outputs": [],
      "source": [
        "# Here's an example training loop using this two-layer model. Can you do better? \n",
        "learning_rate = 0.01  \n",
        "num_examples = x_train.shape[0]\n",
        "batch_size = 10000\n",
        "num_batches = int(num_examples / batch_size)\n",
        "num_epochs = 10\n",
        "losses = numpy.zeros(num_batches*num_epochs,)\n",
        "indices = numpy.arange(num_examples)\n",
        "\n",
        "i = 0\n",
        "for epoch in range(0, num_epochs):\n",
        "    # in each epoch, we loop over all of the training examples\n",
        "    for step in range(0, num_batches):\n",
        "        # grabbing the next batch\n",
        "        offset = step * batch_size\n",
        "        batch_range = range(offset, offset+batch_size)\n",
        "        x_train_batch = x_train[batch_range, :]\n",
        "        y_train_batch = y_train_onehot[batch_range,:]\n",
        "        \n",
        "        # feed the next batch in to do one sgd step\n",
        "        loss, model = learn(model, x_train_batch, y_train_batch, learning_rate)\n",
        "        losses[i] = loss\n",
        "        i += 1\n",
        "\n",
        "    acc = accuracy(model, x_train, y_train)\n",
        "    print(\"epoch %d, loss %.5f, accuracy %.2f\" % (epoch, loss, acc))\n",
        "    \n",
        "    # reshuffle the data so that we get a new set of batches\n",
        "    numpy.random.shuffle(indices)\n",
        "    x_train = x_train[indices,:]\n",
        "    y_train = y_train[indices] # keep this shuffled the same way for use in accuracy calculation\n",
        "    y_train_onehot = y_train_onehot[indices,:]\n",
        "plt.plot(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4f274c6",
      "metadata": {
        "id": "a4f274c6"
      },
      "outputs": [],
      "source": [
        "accuracy(model, x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6f87bb0",
      "metadata": {
        "id": "d6f87bb0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Homework: change parameters to try to improve learning**"
      ],
      "metadata": {
        "id": "7AEsjuBp8fxK"
      },
      "id": "7AEsjuBp8fxK"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OP-lf8Ys8nEb"
      },
      "id": "OP-lf8Ys8nEb",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}